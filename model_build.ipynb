{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Persisting an ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/student-mat.csv', sep=';')\n",
    "# df.describe()\n",
    "# df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the quality of the student. We will build a predictor based on the final grade (G3).\n",
    "Because we are trying to find quality students. In this model we define a quality student as one who achieves a final grade of 15 or higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import scikit-learn and build a random forest classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'Medu' 'failures' 'Dalc' 'Walc' 'absences' 'G1' 'G2' 'schoolsup'\n",
      " 'internet']\n",
      "TRAIN:accuracy = 0.9864864864864865,\tF1 = 0.96\n",
      "TEST: accuracy = 0.9696969696969697,\tF1 = 0.9333333333333332\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Lists of all useable features in df (except 'G3' and 'qual_student')\n",
    "all_features = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "    'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "    'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "    'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "    'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "all_numerical_features = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
    "    'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "\n",
    "\n",
    "# Get all data\n",
    "df['qual_student'] = np.where(df['G3']>=15, 1, 0)    \n",
    "X = df[all_features]\n",
    "y = df['qual_student']\n",
    "\n",
    "# Categorical vs Numerical Preprocessing\n",
    "# To find out how to split and use both numerical and categorical features, see \n",
    "# https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html\n",
    "numerical_selector   = make_column_selector(dtype_include='number')\n",
    "categorical_selector = make_column_selector(dtype_exclude='number')\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('standard_scalar', StandardScaler(), numerical_selector),  # numerical features\n",
    "    ('one_hot_encoder', OrdinalEncoder(), categorical_selector) # categorical features\n",
    "    ], verbose_feature_names_out=False)                         # no feature prefixes\n",
    "\n",
    "# Select k best features in X\n",
    "# k=3:  ['Medu', 'G1', 'G2']\n",
    "# k=5:  ['Medu', 'failures', 'absences', 'G1', 'G2']\n",
    "# k=10: ['age', 'Medu', 'failures', 'Dalc', 'Walc', 'absences', 'G1', 'G2', 'schoolsup', 'internet']\n",
    "selector = make_pipeline(preprocessor, SelectKBest(k=10))\n",
    "include = selector.fit(X, y).get_feature_names_out()\n",
    "print(include)\n",
    "\n",
    "# Reduce data to the k best features\n",
    "X_reduced = X[include]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=42)\n",
    "\n",
    "# Train the model using Logistic Regression. Use GridSearchCV to find params\n",
    "parameters = {\n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "search = GridSearchCV(LogisticRegression(),     # model\n",
    "                    param_grid = parameters,    # hyperparameters\n",
    "                    scoring='f1',               # metric for scoring\n",
    "                    cv=5)                       # number of folds\n",
    "clf = make_pipeline(preprocessor, search)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get prediction scores\n",
    "def print_scores(X, y):\n",
    "    # Get predictions\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    # Print Scores\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    f1  = f1_score(y, y_pred, average='binary')\n",
    "    print('accuracy = {},\\tF1 = {}'.format(acc, f1))\n",
    "\n",
    "print('TRAIN:', end=' ')\n",
    "print_scores(X_train, y_train)\n",
    "print('TEST: ', end=' ')\n",
    "print_scores(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export this model so we can use it in a microservice (flask api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- absences\n",
      "- age\n",
      "- health\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Dalc\n",
      "- G1\n",
      "- G2\n",
      "- Medu\n",
      "- failures\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but OrdinalEncoder is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m joblib\u001b[39m.\u001b[39mdump(clf, \u001b[39m'\u001b[39m\u001b[39mapp/handlers/model.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m query_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({ \u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m1\u001b[39m) ,\u001b[39m'\u001b[39m\u001b[39mhealth\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m15\u001b[39m) ,\u001b[39m'\u001b[39m\u001b[39mabsences\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m10\u001b[39m)})\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(query_df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mtype\u001b[39m(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/pipeline.py:457\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    455\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 457\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    458\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:1363\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m   1350\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m \u001b[39m    Transform X to ordinal codes.\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39m        Transformed input.\u001b[39;00m\n\u001b[1;32m   1362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m     X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[1;32m   1364\u001b[0m         X, handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown, force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m   1365\u001b[0m     )\n\u001b[1;32m   1366\u001b[0m     X_trans \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mastype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1368\u001b[0m     \u001b[39mfor\u001b[39;00m cat_idx, missing_idx \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_missing_indices\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:141\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m, X, handle_unknown\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, warn_on_unknown\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_names(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    142\u001b[0m     X_list, n_samples, n_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_X(\n\u001b[1;32m    143\u001b[0m         X, force_all_finite\u001b[39m=\u001b[39mforce_all_finite\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    146\u001b[0m     X_int \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_samples, n_features), dtype\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but OrdinalEncoder is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# TODO: Change these lines\n",
    "# modify the file path to where you want to save the model\n",
    "joblib.dump(clf, 'app/handlers/model.pkl')\n",
    "query_df = pd.DataFrame({ 'age' : pd.Series(1) ,'health' : pd.Series(15) ,'absences' : pd.Series(10)})\n",
    "pred = clf.predict(query_df)\n",
    "type(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('se_envir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "621476933c8d5ad44cc784c1dfa91d2ab6cfa115cd86c9e7951c974eb4870de9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
