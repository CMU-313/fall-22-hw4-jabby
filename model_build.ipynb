{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Persisting an ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
       "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
       "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
       "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
       "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
       "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
       "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
       "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
       "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
       "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
       "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
       "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
       "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
       "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
       "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
       "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
       "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
       "\n",
       "[395 rows x 33 columns]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/student-mat.csv', sep=';')\n",
    "df.describe()\n",
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the quality of the student. We will build a predictor based on the final grade (G3).\n",
    "Because we are trying to find quality students. In this model we define a quality student as one who achieves a final grade of 15 or higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import scikit-learn and build a random forest classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medu' 'failures' 'Dalc' 'G1' 'G2']\n",
      "accuracy = 0.9822784810126582,\tF1 = 0.9503546099290779\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Lists of all useable features in df (except 'G3' and 'qual_student')\n",
    "# PROBLEM: linear/logistic regression can't use categorical features (eg. school, sex)!\n",
    "all_features = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "    'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "    'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "    'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "    'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "all_numerical_features = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
    "    'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "\n",
    "\n",
    "# Return x (reduced features) and y (qual_student labels)\n",
    "def parse_data(df, include):\n",
    "    df['qual_student'] = np.where(df['G3']>=15, 1, 0)\n",
    "    \n",
    "    x = df[include]\n",
    "    y = df['qual_student']\n",
    "    return x, y\n",
    "\n",
    "# Print accuracy/F1\n",
    "def print_scores(y, pred):\n",
    "    print('accuracy = {},\\tF1 = {}'.format( \\\n",
    "        accuracy_score(y, pred), f1_score(y, pred, average='binary')) )\n",
    "\n",
    "# TODO: PROBLEM: current pipeline treats all features as categorical (in OrdinalEncoder)\n",
    "# This means that during testing, unseen numerical features (e.g. G2=\"1\") won't be recognized!\n",
    "# to find out what to do, see \n",
    "# https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html\n",
    "\n",
    "# Select the best k features to use\n",
    "# k=5: ['Medu', 'failures', 'absences', 'G1', 'G2']\n",
    "x, y = parse_data(df, all_features)\n",
    "k = 5\n",
    "selector = make_pipeline(OrdinalEncoder(), SelectKBest(k=k))\n",
    "include = selector.fit(x, y).get_feature_names_out()\n",
    "print(include)\n",
    "\n",
    "# Build ML model using best k features\n",
    "x, y = parse_data(df, include)\n",
    "clf = make_pipeline(OrdinalEncoder(), LogisticRegression())\n",
    "clf.fit(x, y)\n",
    "\n",
    "# Get prediction scores\n",
    "pred = clf.predict(x)\n",
    "print_scores(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not very good! We didn't even cross validate. You'll need to do better :)\n",
    "Let's export this model so we can use it in a microservice (flask api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- age\n",
      "- health\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- G1\n",
      "- G2\n",
      "- Medu\n",
      "- failures\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but LogisticRegression is expecting 5 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m joblib\u001b[39m.\u001b[39mdump(clf, \u001b[39m'\u001b[39m\u001b[39mapp/handlers/model.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m query_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({ \u001b[39m'\u001b[39m\u001b[39mage\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m1\u001b[39m) ,\u001b[39m'\u001b[39m\u001b[39mhealth\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m15\u001b[39m) ,\u001b[39m'\u001b[39m\u001b[39mabsences\u001b[39m\u001b[39m'\u001b[39m : pd\u001b[39m.\u001b[39mSeries(\u001b[39m10\u001b[39m)})\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(query_df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/brandon/Documents/GitHub/fall-22-hw4-jabby/model_build.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mtype\u001b[39m(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/se_envir/lib/python3.8/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but LogisticRegression is expecting 5 features as input."
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# TODO: Change these lines\n",
    "# modify the file path to where you want to save the model\n",
    "joblib.dump(clf, 'app/handlers/model.pkl')\n",
    "query_df = pd.DataFrame({ 'age' : pd.Series(1) ,'health' : pd.Series(15) ,'absences' : pd.Series(10)})\n",
    "pred = clf.predict(query_df)\n",
    "type(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('se_envir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "621476933c8d5ad44cc784c1dfa91d2ab6cfa115cd86c9e7951c974eb4870de9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
