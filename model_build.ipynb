{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Persisting an ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/student-mat.csv', sep=';')\n",
    "# df.describe()\n",
    "# df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to predict the quality of the student. We will build a predictor based on the final grade (G3).\n",
    "Because we are trying to find quality students. In this model we define a quality student as one who achieves a final grade of 15 or higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import scikit-learn and build a random forest classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['failures', 'absences', 'G1', 'G2']\n",
      "TRAIN: accuracy = 0.9864864864864865,\tF1 = 0.9591836734693877\n",
      "TEST:  accuracy = 0.9696969696969697,\tF1 = 0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Lists of all useable features in df (except 'G3' and 'qual_student')\n",
    "all_features = ['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
    "    'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
    "    'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
    "    'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
    "    'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "all_numerical_features = ['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
    "    'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n",
    "\n",
    "\n",
    "# Get all data\n",
    "df['qual_student'] = np.where(df['G3']>=15, 1, 0)    \n",
    "X = df[all_features]\n",
    "y = df['qual_student']\n",
    "\n",
    "# Categorical vs Numerical Preprocessing\n",
    "# To find out how to split and use both numerical and categorical features, see \n",
    "# https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html\n",
    "numerical_selector   = make_column_selector(dtype_include='number')\n",
    "categorical_selector = make_column_selector(dtype_exclude='number')\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('standard_scalar', StandardScaler(), numerical_selector),  # numerical features\n",
    "    ('one_hot_encoder', OrdinalEncoder(), categorical_selector) # categorical features\n",
    "    ], verbose_feature_names_out=False)                         # no feature prefixes\n",
    "\n",
    "# Select k best features in X\n",
    "selector = make_pipeline(preprocessor, SelectKBest(k=5))\n",
    "include = selector.fit(X, y).get_feature_names_out()\n",
    "# k=5:  ['Medu', 'failures', 'absences', 'G1', 'G2']\n",
    "# however, let's remove 'Medu' because may be too personal\n",
    "include = ['failures', 'absences', 'G1', 'G2']\n",
    "print(include)\n",
    "\n",
    "# Reduce data to the k best features\n",
    "X_reduced = X[include]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, random_state=42)\n",
    "\n",
    "# Train the model using Logistic Regression. Use GridSearchCV to find params\n",
    "parameters = {\n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}\n",
    "numerical_selector   = make_column_selector(dtype_include='number')\n",
    "categorical_selector = make_column_selector(dtype_exclude='number')\n",
    "preprocessor = StandardScaler() # we can do this b/c all features are numerical now\n",
    "search = GridSearchCV(LogisticRegression(),     # model\n",
    "                    param_grid = parameters,    # hyperparameters\n",
    "                    scoring='f1',               # metric for scoring\n",
    "                    cv=5)                       # number of folds\n",
    "clf = make_pipeline(preprocessor, search)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get prediction scores\n",
    "def print_scores(X, y):\n",
    "    # Get predictions\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    # Print Scores\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    f1  = f1_score(y, y_pred, average='binary')\n",
    "    print('accuracy = {},\\tF1 = {}'.format(acc, f1))\n",
    "\n",
    "print('TRAIN:', end=' ')\n",
    "print_scores(X_train, y_train)\n",
    "print('TEST: ', end=' ')\n",
    "print_scores(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export this model so we can use it in a microservice (flask api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# TODO: Change these lines\n",
    "# modify the file path to where you want to save the model\n",
    "joblib.dump(clf, 'app/handlers/model.pkl')\n",
    "query_df = pd.DataFrame({ 'failures' : pd.Series(3),\n",
    "                          'absences' : pd.Series(3),\n",
    "                          'G1' : pd.Series(7),\n",
    "                          'G2' : pd.Series(11)})\n",
    "pred = clf.predict(query_df)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('se_envir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "621476933c8d5ad44cc784c1dfa91d2ab6cfa115cd86c9e7951c974eb4870de9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
